import json
import os
import base64
import asyncio
from openai import AsyncOpenAI
from PIL import Image
from io import BytesIO
from tqdm.asyncio import tqdm_asyncio
import yaml

# ==================== å…¨å±€é…ç½® ====================

BASE_DIR = os.path.abspath(os.path.dirname(__file__))

with open(os.path.join(BASE_DIR, 'config.yaml'), encoding='utf-8') as f:
    CONFIG = yaml.safe_load(f)

INPUT_JSON_PATH = CONFIG['path']['metadata']
OUTPUT_JSON_PATH = CONFIG['inference']['output_result_file']
os.makedirs(os.path.dirname(OUTPUT_JSON_PATH), exist_ok=True)

VLLM_API_BASE = CONFIG['inference']['base_url']
MODEL_NAME = CONFIG['inference']['model_name']
MAX_CONCURRENT = CONFIG['inference']['concurrency_limit']
MAX_RETRIES = CONFIG['inference']['max_retries']
PROMPT_TEMPLATE = CONFIG['inference']['incitement_prompt']
SYSTEM_PROMPT = CONFIG['inference']['system_prompt']
MAX_TOKENS = CONFIG['inference']['max_new_tokens']
TEMPERATURE = CONFIG['inference']['temperature']

# ==================== å·¥å…·å‡½æ•° ====================

def encode_image_to_base64(image_path: str) -> str:
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"å›¾åƒä¸å­˜åœ¨: {image_path}")
    with Image.open(image_path) as img:
        # è½¬ä¸º RGBï¼ˆé˜²æ­¢ RGBA é—®é¢˜ï¼‰
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
        buffer = BytesIO()
        img.save(buffer, format="PNG")
        return "data:image/png;base64," + base64.b64encode(buffer.getvalue()).decode("utf-8")

# ==================== æ¨ç†å‡½æ•° ====================

async def run_single_inference(
    client: AsyncOpenAI,
    semaphore: asyncio.Semaphore,
    item: dict
) -> dict:
    idx = item["id"]
    question = item["question"]
    img_path = item["img_path"]

    async with semaphore:
        try:
            base64_image = encode_image_to_base64(img_path)
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user",
                "content": [
                    {"type": "text", "text": PROMPT_TEMPLATE},
                    {"type": "image_url", "image_url": {"url": base64_image}}
                ]
            }]

            for attempt in range(MAX_RETRIES):
                try:
                    response = await client.chat.completions.create(
                        model=MODEL_NAME,
                        messages=messages,
                        max_tokens=MAX_TOKENS,
                        temperature=TEMPERATURE
                    )
                    return {
                        "id": idx,
                        "question": question,
                        "img_path": img_path,
                        "response": response.choices[0].message.content.strip()
                    }
                except Exception as e:
                    if attempt == MAX_RETRIES - 1:
                        return {
                            "id": idx,
                            "question": question,
                            "img_path": img_path,
                            "response": f"[ERROR] Retry {MAX_RETRIES} failed: {str(e)}"
                        }
                    await asyncio.sleep(1 * (attempt + 1))
        except Exception as e:
            return {
                "id": idx,
                "question": question,
                "img_path": img_path,
                "response": f"[CRITICAL ERROR] {str(e)}"
            }

# ==================== ä¸»å‡½æ•° ====================

async def main():
    client = AsyncOpenAI(base_url=VLLM_API_BASE, api_key="token-abc123")
    semaphore = asyncio.Semaphore(MAX_CONCURRENT)

    with open(INPUT_JSON_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        raise ValueError("è¾“å…¥ JSON å¿…é¡»æ˜¯åˆ—è¡¨")

    tasks = []
    for item in data:
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        if not all(k in item for k in ["id", "question", "img_path"]):
            # æ„é€ ç¼ºå¤±é¡¹ï¼ˆå°½é‡ä¿ç•™ idï¼‰
            idx = item.get("id", 0)
            tasks.append(asyncio.create_task(asyncio.sleep(0, {
                "id": idx,
                "question": item.get("question", ""),
                "img_path": item.get("img_path", ""),
                "response": "[SKIPPED] Missing required fields"
            })))
        else:
            tasks.append(run_single_inference(client, semaphore, item))

    print(f"ğŸ“Š å…± {len(data)} æ¡æ•°æ®ï¼Œæœ€å¤§å¹¶å‘: {MAX_CONCURRENT}")
    results = await tqdm_asyncio.gather(*tasks, desc="ğŸ§  æ¨ç†ä¸­")

    # æŒ‰ id æ’åºï¼ˆå¯é€‰ï¼Œå› è¾“å…¥å·²æœ‰åºï¼‰
    results.sort(key=lambda x: x["id"])

    with open(OUTPUT_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ {OUTPUT_JSON_PATH}")

if __name__ == "__main__":
    asyncio.run(main())